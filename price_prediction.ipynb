{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1BCEf2mvh9YXf5vUjBXMoAMAw-JzzhkNs",
      "authorship_tag": "ABX9TyOyjZti5m7MbiYc3G5rHt2b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhas10bc/my-repo/blob/main/price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf### models\n",
        "import pandas as pd ### reading and processing data\n",
        "import seaborn as sns ### visualization\n",
        "import numpy as np### math computations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "from tensorflow.keras.layers import Normalization, Dense, InputLayer\n",
        "from tensorflow.keras.losses import MeanSquaredError, Huber, MeanAbsoluteError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "y6B9P9S2xSoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ge05Bgmf5YRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"train.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "ZhG4zJlP509q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "sWCwCRDp7tdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data[['v.id','on road old','on road now','years','km','rating','condition','economy','top speed','hp','torque','current price']])"
      ],
      "metadata": {
        "id": "orHdgoEr8GsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_data = tf.constant(data)\n",
        "tensor_data = tf.cast(tensor_data, tf.float32)\n",
        "print(tensor_data)"
      ],
      "metadata": {
        "id": "q8I4WUiuEySH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_data = tf.random.shuffle(tensor_data)\n",
        "print(tensor_data[:5])"
      ],
      "metadata": {
        "id": "ImYObggM8FqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tensor_data[:,3:-1]\n",
        "print(X[:5])"
      ],
      "metadata": {
        "id": "R4ms9AyHFUo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y = tensor_data[:,-1]\n",
        "print(y[:5].shape)\n",
        "y = tf.expand_dims(y, axis = -1)\n",
        "print(y[:5])"
      ],
      "metadata": {
        "id": "5FmvjjkB8NEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "normalizer = Normalization(axis = -1, mean = 5, variance = 4)\n",
        "x_normalized = tf.constant([[3,4,5,6,7],\n",
        "                            [4,5,6,7,8]])\n",
        "normalizer(x_normalized)"
      ],
      "metadata": {
        "id": "NIzlyFnvx6Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "normalizer = Normalization()\n",
        "x_normalized = tf.constant([[3,4,5,6,7],\n",
        "                            [4,10,6,7,8],\n",
        "                            [32,1,56,3,5]])\n",
        "normalizer.adapt(x_normalized)\n",
        "normalizer(x_normalized)"
      ],
      "metadata": {
        "id": "OSQjy3Tmx9GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0wLLkJ4yBTO",
        "outputId": "0679b184-7b6e-47fa-f196-fb399077da73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_RATIO = 0.8\n",
        "VAL_RATIO = 0.1\n",
        "TEST_RATIO = 0.1\n",
        "DATASET_SIZE = len(X)"
      ],
      "metadata": {
        "id": "jWV6RU8Nws5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X[:int(DATASET_SIZE*TRAIN_RATIO)]\n",
        "y_train = y[:int(DATASET_SIZE*TRAIN_RATIO)]\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "SRT_vKNuxDEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "OYbRWA4C9NJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = X[int(DATASET_SIZE*TRAIN_RATIO):int(DATASET_SIZE*(TRAIN_RATIO+VAL_RATIO))]\n",
        "y_val = y[int(DATASET_SIZE*TRAIN_RATIO):int(DATASET_SIZE*(TRAIN_RATIO+VAL_RATIO))]\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "id": "F31eZbEBxc0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "val_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "pbW0HEpk9RTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X[int(DATASET_SIZE*(TRAIN_RATIO+VAL_RATIO)):]\n",
        "y_test = y[int(DATASET_SIZE*(TRAIN_RATIO+VAL_RATIO)):]\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "metadata": {
        "id": "gixdJVB0yMwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "test_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "_Dlh1W0f9U5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tensor_data[:,-1]\n",
        "y = tf.expand_dims(y,axis = -1)"
      ],
      "metadata": {
        "id": "wA3HmfXRGl1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = Normalization()\n",
        "normalizer.adapt(X_train)\n",
        "normalizer(X)[:5]"
      ],
      "metadata": {
        "id": "Z225L6p8IfRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             InputLayer(input_shape = (8,)),\n",
        "                             normalizer,\n",
        "                             Dense(128, activation = \"relu\"),\n",
        "                             Dense(128, activation = \"relu\"),\n",
        "                             Dense(128, activation = \"relu\"),\n",
        "                             Dense(1),\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "CIO6S4eiLw_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tf.keras.utils.plot_model(model, to_file = \"model.png\", show_shapes=True)"
      ],
      "metadata": {
        "id": "wesbtalhL6Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = Adam(learning_rate = 0.1),\n",
        "              loss = MeanAbsoluteError(),\n",
        "              metrics = RootMeanSquaredError())"
      ],
      "metadata": {
        "id": "u36CWCfkRizJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs = 100, verbose = 1)"
      ],
      "metadata": {
        "id": "ab2_AToTpdIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SqkhqzeZsaVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['root_mean_squared_error'])\n",
        "plt.plot(history.history['val_root_mean_squared_error'])\n",
        "plt.title('model performance')\n",
        "plt.ylabel('rmse')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jE2LVtV2uGod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history"
      ],
      "metadata": {
        "id": "eRuG-U9MuSFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "HiIVKi3NuZVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.predict(tf.expand_dims(X_test[0], axis = 0 ))"
      ],
      "metadata": {
        "id": "AC8T3nOW1zYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[0]"
      ],
      "metadata": {
        "id": "ytrg1DmY2ve9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = list(y_test[:,0].numpy())"
      ],
      "metadata": {
        "id": "zrY_AXBn6-j1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred = list(model.predict(X_test)[:,0])\n",
        "print(y_pred)"
      ],
      "metadata": {
        "id": "_GQrV7tb7KDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input_data = tf.constant([[3000, 40000, 50000, 60000, 70000,80,90,100]])"
      ],
      "metadata": {
        "id": "om_2RS_X56t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_predictions = model.predict(sample_input_data)\n",
        "\n",
        "# Extract and print the predicted values\n",
        "sample_predicted_values = list(sample_predictions[:, 0])\n",
        "print(sample_predicted_values)"
      ],
      "metadata": {
        "id": "xe3oijBT6BMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind = np.arange(100)\n",
        "plt.figure(figsize=(40,20))\n",
        "\n",
        "width = 0.1\n",
        "\n",
        "plt.bar(ind, y_pred, width, label='Predicted Car Price')\n",
        "plt.bar(ind + width, y_true, width, label='Actual Car Price')\n",
        "\n",
        "plt.xlabel('Actual vs Predicted Prices')\n",
        "plt.ylabel('Car Price Prices')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fy9N_u5P9670"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}